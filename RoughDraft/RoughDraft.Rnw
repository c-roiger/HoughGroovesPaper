\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,mathrsfs,fancyhdr,syntonly,lastpage,hyperref,enumitem,graphicx,subcaption, tikz}

\usepackage[thmmarks,thref]{ntheorem}

\theoremstyle{nonumberplain}
\theoremheaderfont{\itshape}
\theorembodyfont{\upshape}
\theoremseparator{.}
\theoremsymbol{\ensuremath{\square}}
\newtheorem{solution}{Solution}

\hypersetup{colorlinks=true,urlcolor=black}

\topmargin      -1.5cm   % read Lamport p.163
\oddsidemargin  -0.04cm  % read Lamport p.163
\evensidemargin -0.04cm  % same as oddsidemargin but for left-hand pages
\textwidth      16.59cm
\textheight     23.94cm
\parskip         7.2pt   % sets spacing between paragraphs
\parindent         0pt   % sets leading space for paragraphs
\pagestyle{empty}        % Uncomment if don't want page numbers
\pagestyle{fancyplain}


\begin{document}
\SweaveOpts{concordance=TRUE}
\lhead{\today}
\chead{CSAFE - Hough Grooves Document Process}
\rhead{Page \thepage\ of \pageref{LastPage}}

\section{Introduction}
I do not know how to start introductions!!!!!! 
\section{Methods}


\subsection{Brief Overview of Hough Transforms}


In broad terms, the Hough Transform is a feature extraction technique for detecting shapes in an image. For any given point in the (x,y)-plane of our image we can calculate a corresponding line in the feature space. Points that lie on the same line will have lines that intersect in the feature space. 
\begin{figure}[!ht]
\begin{subfigure}{.5\textwidth}
\centering
\begin{tikzpicture}
\draw [<->] (0,-6) node (yaxis) [below] {$y$} -- (0,0) -- (6,0) node (xaxis) [right] {$x$};
\draw [ultra thick] (0.5,-0.5) -- (5.5, -5.5);
\draw [fill = cyan] (1.5,-1.5) circle [radius=0.2];
\node [] at (2.5, -1.5) {($x_{i}, y_{i}$)};
\draw [fill = orange] (3.5,-3.5) circle [radius=0.2];
\node [] at (4.5, -3.5) {($x_{j}, y_{j}$)};
\node [] at (6,-6) {$y = ax + b$};
\end{tikzpicture}
\label{fig: tikz1}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\centering
\begin{tikzpicture}
\draw [<->] (0,-6) node (yaxis) [below] {$b$} -- (0,0) -- (6,0) node (xaxis) [right] {$a$};
\draw[cyan, ultra thick] (0.5, -1) -- (6,-3);
\node [] at (2, -5.5) {$b=x_{j}a + y_{j}$};
\node [] at (2.5, -1) {$b=-x_{i}a + y_{i}$};
\draw[orange, ultra thick] (0.5, -5) -- (6,-0.5);
\draw [fill] (3.89,-2.23) circle [radius=0.2];
\node [] at (3.89, -3) {($a, b$)};
\end{tikzpicture}
\label{fig: tikz2}
\end{subfigure}
\caption{Diagram of feature space linea transformation oriented for image origin.}
\label{fig: parametrization}
\end{figure}


The point of intersection in the feature space, then corresponds to the parameters used to describe the edge in the (x,y)-plane that the two detected points lie upon. A two dimensional array called the "accumulator array" is used to keep track of features detected.  The accumulator array covers the entirety of the feature space separated into a user-specified number of bins. For each set of features detected the bin in the accumulator array associated with that set of features is incremented. So in theory, strong features should have higher values in their associated bin because 


In order to best identify the GEAs we first want to diminish noise in the image. This can be achieved by converting each scan into an image gradient, which signifies where there are directional changes in the color of the image. This approach unforunately loses most of the detail of the three dimensional scans, however, it better highlights the differences between LEAs and GEAs. Once an image gradient is obtained we select only edges we consider to be "strong", meaning they have a magnitude above the 99th percentile. Our reason for not fully carrying out a Canny Edge detection algorithm before using a Hough transform is that the Canny Edge algorithm increases processing time by about 35 seconds per image and actually highlights more striae and breakoff. 

\begin{figure}[!ht]
    \centering
    \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width = .9\textwidth]{../images/Hamby252_Bullet1_Land3_Strong_edge.png}
      \caption{Edges with magnitudes in the 99th percentile}
      \label{fig: edge1}
      \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width = .9\textwidth]{../images/Hamby252_Bullet1_Land3_Canny_Edge.png}
      \caption{Edges improved with Canny edge detection}
      \label{fig: edge2}
      \end{subfigure}
      \caption{Side-by-side comparison of Hamby 252 Bullet using both magnitude thresholding and Canny edge detection}
      \label{fig: canny}
\end{figure}

As shown in Figure \ref{fig: canny} the striae in the LEA are much more pronunced than in the image with only strong edges. We wish to focus on only detecting GEAs, so detecting an increased number of striae through Canny edge detection is not useful for our algorithm. Once we obtain the image gradient with only the strong edges we can then utilize our Hough transformation to obtain generally reasonable estimates of image boundaries. For the Hough transformation we utilize the function `` \texttt{hough\char`_lines}" from the imager package with the number of bins set to 100. While changing the number of bins does not seem to effect the processing time of the Hough transform, having a larger number of bins increases the number of extraneous detected lines in the image. For example in Figure \ref{fig: hough-compare}\subref{fig: hough1} we can see that the Hough transforms with 100 bins does a perfectly aedequate job of picking up the suspected grooves of the bullet. Therefore the extra detected lines in \ref{fig: hough-compare}\subref{fig: hough2} are not used in our analysis so we chose to limit our bin number as a result.

\begin{figure}[!ht]
    \centering
      \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width = .9\textwidth]{../images/Houston_BarrelF_Bullet1_Hough_Bin100}
      \caption{Hough Transform with 100 bins}
      \label{fig: hough1}
      \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \centering
      \includegraphics[width = .9\textwidth]{../images/Houston_BarrelF_Bullet1_Hough_Bin900}
      \caption{Hough Transform with 900 bins}
      \label{fig: hough2}
      \end{subfigure}
      \caption{Side-by-side comparison of Houston Barrel F Land 1 Hough Transformation. Hough lines are filtered by having scores in the 99.9th percentile, and having central angles less than $\frac{\pi}{16}$.}
      \label{fig: hough-compare}
\end{figure}

We make the assumption that scans are oriented properly and as such, most Hough lines that correlate to the GEAs will be roughly vertical with some deviations in angle based on scanning technique. It is worth noting that the original output of the `` \texttt{hough\char`_lines}" functions have angles ranging from 0 to $2\pi$. So to make selecting lines from our desired range, easier we chose to transform any angle greater than $\pi$, to instead be from 0 to $-\pi$ by subtracting $2\pi$ from the original theta angle. Therefore we select only the Hough lines that have theta angles from the positive x-axis less than $\frac{\pi}{16}$ and greater than $\frac{-\pi}{16}$. The parametrization produced by `` \texttt{hough\char`_lines}" is of the form:

\begin{center}
$\rho = x \ cos(\theta) \ + \ y \ sin(\theta)$
\end{center}

Where $\rho$ represents the length of the normalized orthogonal vector between the detected line and the origin of the image, and $\theta$ is the angle between the positive x-axis and the normalized vector. We note that the format of bullet images is slightly different from standard x-y-plots. In two-dimensional representations of bullet images, the y-axis is inverted from what we would expect. A reason for this is that the images are processed in \textbf{C++} which stores images, known as ``CImgs'' in a vector format where the first pixel in the vector corresponds to the upper lefthand pixel of the image located at (0,0). Pixels are then ordered from left to right, extending from the origin to the positive x-direction and from top to bottom, from the x-axis towards the negative y-direction. In Figure \ref{fig: parametrization} we see an example of how Hough transforms parametrize a line. In this figure, the orange line represents an example of a detected Hough line. The teal line connecting the origin to the orthogonal bisector of our detected Hough line represents the vector denoted $\rho$ in our above equation. Similarly the teal arc below represents the angle, $\theta$, which is the difference between the top of the image and the orthogonal bisector. 

\begin{figure}[ht!]
  \centering
  \includegraphics{../images/hessian-example.png}
  \caption{Example of Hessian Normal Form parametrization overlaid a bullet scan}
  \label{fig: parametrization}
\end{figure}

We note that when $\theta$ is equal to 0, the x-intercept is given by $\rho$ however when $\theta$ is not 0 we utilize the above equation to find that the x-intercept is equivalent to $\frac{\rho}{\cos(\theta)}$.  We utilize this calculation to find where the estimated Hough line intersects the top and bottom of the bullet land. The top is the x-intercept calculated previously, however to calculate the bottom intersection of the bullet land we utilize some geometric properties. We can draw a perpendicular line from the x-intercept at the top of the land to the bottom of the land creating a right triangle as shown below in \ref{fig: calcxbottom}. Since both the angle between the orthogonal bisector labeled $\rho$ and the new triangle created from the xintercept to the bottom of the land are both right triangles, we know that the angle at the top of the newly formed triangle is equivalent to $\theta$. Since the x-intercept is known, we can use an elementary geometry technique to calculate the distance labelled $\delta$ in the diagram below. Since $\tan(\theta)$ is equivalent to the proportion of the length of the ``opposite" side over the ``adjacent" side of the right triangle, we know that $\delta = \tan(\theta)*\text{height}$. So the index of the bottom intersection of the bullet land is equivalent to top-intersection - $\delta$. 

\begin{figure}[ht!]
  \centering
  \includegraphics{../images/calc-xbottom.png}
  \caption{Demonstration of calculation of bottom intercept of a bullet land using SOH-CAH-TOA}
  \label{fig: calcxbottom}
\end{figure}

The utility for calculating the top and bottom intercept of our bullet land is that it allows us to calculate the slope of each Hough line with respect to the y-direction. 
\begin{center}
\text{Slope \ with \ respect \ to \ y} = $\frac{(\text{x-intercept of the top} - \text{x-intercept of the bottom})}{\text{height of the bullet land}}$
\end{center}

Traditionally slope with respect to the x-direction is chosen for describing the equation of a line, however, because we are primarily interested in vertical lines the slope with respect to the x-direction tends to infinity. This is undesireable for a number of reasons, and so we have decided to use the slope with respect to y because it is more robust for describing Hough lines. 

As discussed before, the Hough transform outputs a sort of score that correpsonds to the number of pixels detected on a line that can give us an indication of the strength of the feature detected. Theoretically, we would expect the strongest lines in our image to be the grooves on either side of the bullet land. So the problem arises of how best to select strong edges. Rather than simply filter scores on some arbitrary threshold, we normalize the Hough scores by the largest possible score that could be achieved for each set of features detected. The reason for this is that longer lines will have a larger Hough score, simply by virtue of having a larger number of possible detectable pixels.  

\begin{figure}[ht!]
  \centering
  \includegraphics{../images/calc-theoretical-max.png}
  \caption{Demonstration of calculation of theoretical maximum Hough score using SOH-CAH-TOA}
  \label{fig:calcmaxscore}
\end{figure}


We calculate the largest possible theoretical score by dividing the height of the image by $\cos(\theta)$. This should in theory give us the total possible pixels that the Hough transform could have detected in our image by exploiting geometric properties of the right triangle shown in figure \ref{fig:calcmaxscore}. Then for each unique set of features that describe a line that the Hough transform detects we divide the score associated with these features by the theoretical maximum score, yielding the normalized score. To further specify the best candidates for the bullet land grooves, we rely on the heuristic that most of the middle 50\% of the bullet will be occupied by striae. Therefore, we can eliminate any strong lines detected within this region. An example of the middle fifty percent of a bullet land can be seen in figure \ref{fig:middlefifty} where the middle fifty percent of the bullet land is bordered by cyan coloured vertical lines. We note that the grooves are well away from this middle fifty percent region, making this a suitable heuristic. We then select the highest normalized score of the lines detected outside of the middle fifty percent of the bullet land. We claim then that this is our detected bullet groove. 
\begin{figure}[ht!]
  \centering
  \includegraphics{../images/phnx-1-m2-b1-l1-middle-fifty-demo.png}
  \caption{Middle fifty percent of the bullet land marked by two cyan coloured vertical lines imposed over the Phoenix set Gun 1-M2 Bullet 1 Land 1 scan}
  \label{fig:middlefifty}
\end{figure}
<<r, eval=FALSE, echo=FALSE>>=
x3p <- read_x3p("../../../../../Volumes/Samsung_T3/Phoenix/Gun 1-M2/B1/L1.x3p")
pix_to_micron <- function(x, land) {
  assert_that(is.numeric(x))
  (x - 1) * x3p_get_scale(land)
}

lfourth <- width(x3p$surface.matrix)/4
ufourth <- 3*width(x3p$surface.matrix)/4
mask <- matrix(
    data = FALSE,
    nrow = ncol(x3p$surface.matrix),
    ncol = nrow(x3p$surface.matrix)
  )

a <- x3p %>% x3p_add_mask_layer(mask = mask)
a <- a %>% x3p_add_vline(xintercept = pix_to_micron(lfourth, a), color = "cyan", size = 10)
a <- a %>% x3p_add_vline(xintercept = pix_to_micron(ufourth, a), color = "cyan", size = 10)
x3ptools::image_x3p(a)
@





\end{document}
